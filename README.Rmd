---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# actdata

<!-- badges: start -->
<!-- badges: end -->

This package is intended to be a repository for standarized versions of all publicly released affect control theory dictionaries and equations. These datasets are currently stored in several different places and in several different formats. Standardizing them and providing them together in one R package is intended to make them easier to access and make part of a reproducible analysis workflow.

Details on standarization procedures for dictionaries and equation sets as well as instructions for how to access the data in this package are provided below. 

## Installation

You can install the development version of actdata from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("ahcombs/actdata")
```

## Dictionaries

This package makes available 25 affect control theory dictionaries that have been publicly released. These dictionaries span nearly 45 years and have been collected in many locations around the world. 

To see details--including descriptions and citation information--for the dictionaries available, call `dict_info()`. Include a dictionary key as an argument to see information for just that dictionary: 

```{r}
library(actdata)
dict_info("nc1978")
```

### Naming convention

Dictionary datasets are named according to the following format: 

[key]_[component]_[gender]_[datatype]_dict

* *Key* is an identifier unique to a particular study (e.g. `nc1978`; `morocco2015`). Call `dict_info()` to see the keys for the provided datasets. 
* *Component* indicates what kind of terms are included in the dictionary dataset. Typically, studies provide dictionary datasets with more than one component, but not all studies provide all possible components. Components include: 
    * *identities*: Words that describe actors. Typically nouns (e.g. academic, woman, youngster)
    * *behaviors*: Actions that actors can perform. Typically verbs (e.g. wheedle, acclaim, work)
    * *mods*: Modifiers. Typically adjectives that can be applied to identities (e.g. active, witty, young)
    * *settings*: Places and situations (e.g. airplane, alley, worship_service)
* *Gender* indicates the gender of the participants who rated the terms. Options are `m`, `f`, and `av`. Av (average) indicates that participants of all genders were included, though the way this is calculated differs slightly by dictionary. Some dictionaries (e.g. the 2015 US, Morocco, and Egypt dictionaries) are originally published as average values over raters of all genders. In these cases, `av` is the only provided option. Other dictionaries are originally published in male and female subsets. Average values over all raters are not provided in these originally published sets. In this case, the package calculates an approximate average by averaging the male and female values. Typically, studies recruit approximately equal numbers of men and women and men and women's ratings do not differ substantially on most terms, so we expect these approximate average values to be reasonably close to those that we would obtain from an average over all raters. For these dictionaries that provide male and female subsets separately, the package provides male, female, and approximate average versions. For more information on gender and affect control theory dictionaries, see section 4.1 of David Heise's *Expressive Order* (2007). 
* *Datatype* is used when the desired dictionary provides variance information in addition to mean values. Most research in the affect control theory tradition to date has only utilized mean evaluation, potency, and activity values, and most dictionaries provide only means. However, BayesACT, a recent expansion of affect control theory, makes it possible to use variance information around these means (see Schr√∂der, Hoey, and Rogers's 2016 American Sociological Review publication for description of BayesACT). This package currently includes one dictionary  (uga2015bayesactsubset) with standard deviation and covariance matrix data. The datasets corresponding to this dictionary include `SD` or `COV` in the `datatype` slot, depending on whether they include standard deviation or covariance matrix values. For all other dictionaries, which include means only, leave this slot empty. 

Load data sets using `data()` with the desired data set name as the argument. See information on the structure and size of each data set using `?`.

### Term standardization

To facilitate comparisons between dictionaries, the terms in all have been transformed into a common format. All terms are provided in all-lowercase and spelling and spacing have been made standard across dictionaries (generally, the US spellings are chosen). Spaces are represented by underscores in all dictionaries. Accents have been removed. The code used to perform this standardization is located in `standardize_dict_terms.R`, included in this package. 

### Term tables

One of the main goals of this package is to make it easy to compare across dictionaries. To this end, the package provides four *term tables* that show at a glance which terms are included in which dictionaries. There is one table for each component (identities, behaviors, modifiers, settings). Load these tables into your environment using: 

    * `data("term_table_ident")`
    * `data("term_table_beh")`
    * `data("term_table_mod")`
    * `data("term_table_set")`
    
Each column in these tables represents a dictionary (labeled with its key) and each row is a term. Cell entries (0/1) indicate whether or not the specified dictionary has the specified term. These tables can easily be modified further to generate summaries across a set of dictionaries of interest. 

## Equations

The second kind of data this package makes available are tables containing estimates of affect control theory equation coefficients. These coefficients can be used in conjunction with dictionaries to calculate affective responses to various situations. See section 18.2 of David Heise's *Expressive Order* (2007) for a detailed description of the structure and use of these tables.

To see information on all equation sets available in this package, call `eqn_info()`. All of the available equation sets were originally sourced from Interact (version 2.1 beta, accessed May 2021), and component titles are based on labels applied in Interact.

### Naming convention

The equation datasets are named according to the following convention:

[key]_[component]_[gender]_eqn

* *Key* is a unique identifier for the study in which the equation coefficients were estimated. Some of these overlap with dictionary keys, but not all. All keys can be accessed using `eqn_info()`.
* *Component* indicates the type of equations represented. The following components are possible (more information on each is available in section 18.2 of David Heise's *Expressive Order* (2007)): 
    * *impressionabo*: Impression change equations including actor, behavior, and object terms
    * *impressionabos*: Impression change equations including actor, behavior, object, and setting terms
    * *selfdir*: Equations for self-directed action, including actor and behavior terms.
    * *traitid*: Equations for combining a trait modifier with an identity. In some datasets, this set is the same as the emotionid set.
    * *emotionid*: Equations for combining an emotion modifier with an identity. In some datasets, this set is the same as the traitid set.
* *Gender* indicates the gender of study participants whose ratings are used to estimate the equation coefficients. Options are `m`, `f`, and `av`. Call `dict_info()` to check which genders are available for which dictionaries. Interact, from which all of these equation sets were originally taken, provides male and female-labeled sets for each equation. However, sometimes these sets are identical. In this case, this package simply labels the set as `av` rather than including it twice. All values are provided exactly as they are in Interact--no post-hoc calculations have been performed. 

## Writing files for Interact

Interact allows users to import their own dictionary and equation files. Though many of the dictionaries and equation sets provided here are available in Interact, several are not. Additionally, sometimes it is useful to use subsets of dictionaries (e.g. when a user wants to restrict the identities, behaviors, or modifiers available), and creating these subsets within Interact itself, while possible, is tedious and not easily replicable.

The `save_for_interact(data, type, filename)` function in this package makes it easy to write dictionary and equation .txt files that are correctly formatted for copying and pasting into Interact. The `data` argument should be a dataframe that the user wishes to save (it can be one of those provided, or one created by the user). `type` should be either `dict` or `eqn` (by default, it is set to `dict`). `filename` should be the filepath at which the user wishes to save the file (by default, it saves to the working directory under the name of the dataset). All filepaths must end in .txt. 

## Working within and across dictionaries: an example using the Tidyverse

The Tidyverse makes it easy to create new combinations or subsets of these dictionaries in a way that is completely replicable, and to visualize quantities of interest over time and/or across countries. An example of how these data sets can be used along with `dplyr`, `tidyr`, and `ggplot` is included below.

Say we are interested in comparing changes in evaluation ratings for identities over time in whatever countries possible. First, we look through the available dictionaries to pick ones to use: 

```{r}
dict_info()
```

The three countries in which multiple dictionaries have been collected are the U.S., Canada, and Germany. We choose three U.S. dictionaries (nc1978, texas1998, and usfullsurveyor2015), two Canadian dictionaries (ontario1980 and ontario2001), and two German dictionaries (germany1989 and germany2007). Now we need to find the identity terms that are in all seven dictionaries. The term table is useful to quickly get a first look at this.

```{r}
library(dplyr)

data(term_table_ident)

term_table_short <- term_table_ident %>% 
  # we only need the columns for our chosen dictionaries
  select(term, nc1978, texas1998, usfullsurveyor2015, ontario1980, ontario2001, germany1989, germany2007) %>% 
  # filter to those terms present in all five datasets
  filter(nc1978 + texas1998 + usfullsurveyor2015 + ontario1980 + ontario2001 + germany2007 + germany1989 == 7)

head(term_table_short)
```

We now have a list of the `length(term_table_short)` identities included in all seven dictionaries. Now we need the evaluation values for these terms. These are located in the dictionary objects. I will use the gender averaged datasets here.

```{r}
# there are many valid ways to join datasets together. Here I will use the inner_join function from the dplyr package. 

# load dictionaries into the global environment
data("nc1978_identities_av_dict")
data("texas1998_identities_av_dict")
data("usfullsurveyor2015_identities_av_dict")
data("ontario1980_identities_av_dict")
data("ontario2001_identities_av_dict")
data("germany1989_identities_av_dict")
data("germany2007_identities_av_dict")


# we don't actually need the modified term table we created to generate this subset--inner_join will do the filtering for us. However, it is useful for seeing quickly which terms are in which sets without having to load and manipulate the actual dictionaries. 
identity_subset <- inner_join(nc1978_identities_av_dict, texas1998_identities_av_dict, by = 'term', suffix = c("", ".texas1998")) %>% 
  inner_join(usfullsurveyor2015_identities_av_dict, by = 'term', suffix = c("", ".usfullsurveyor2015")) %>% 
  inner_join(ontario1980_identities_av_dict, by = 'term', suffix = c("", ".ontario1980")) %>% 
  inner_join(germany1989_identities_av_dict, by = 'term', suffix = c("", ".germany1989")) %>% 
  inner_join(germany2007_identities_av_dict, by = 'term', suffix = c("", ".germany2007")) %>% 
  inner_join(ontario2001_identities_av_dict, by = 'term', suffix = c(".nc1978", ".ontario2001")) %>% 
  # we only need the term column and evaluation columns
  select(term, starts_with("E"))

# Note that this data frame is longer (115 rows) than the list of identity terms in all datasets (114 rows). This is because there are multiple entries for some terms in some dictionaries (see "clown"). This is not an error in the package but rather a quirk of the original data. 

head(identity_subset)
```

Now we have a dataframe that contains just the evaluation values for the terms that the five dictionaries share. For visualization purposes, we will transform this dataframe from wide to long using `pivot_longer` from the tidyr package and cut it down to a manageable number of identities by filtering for those that are very positive (E > 2), very negative (E < -2) or neutral (-.15 < E < .15). We will also add in a column for year and a column for country, to aid visualization. 

```{r}
library(tidyr)
identity_subset_toplot <- identity_subset %>% 
  # base filtering on nc1978
  filter(E.nc1978 > 2 |
           E.nc1978 < -2 |
           (E.nc1978 > -.15 & E.nc1978 < .15)) %>%
  pivot_longer(starts_with('E'), 
               names_to = c('place', 'year'), 
               names_prefix = "E\\.", 
               names_sep = -4,
               values_to = "Evaluation") %>% 
  mutate(place = case_when(place %in% c("texas", "nc", "usfullsurveyor") ~ "US",
                           place == 'germany' ~ "Germany", 
                           TRUE ~ "Canada"),
         term = paste0(term, "_", place),
         year = as.numeric(year))
```

Now we can plot this using ggplot.

```{r}
library(ggplot2)
ggplot(identity_subset_toplot, aes(x = year, y = Evaluation, group = term, color = place)) +
  geom_line(alpha = .7)
```

